{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train_loss: 53763.4375\n",
      "step: 1, train_loss: 182405818220544.0\n",
      "step: 2, train_loss: 6.96314076409115e+23\n",
      "step: 3, train_loss: 2.6596782741435e+33\n",
      "step: 4, train_loss: inf\n",
      "step: 5, train_loss: inf\n",
      "step: 6, train_loss: inf\n",
      "step: 7, train_loss: inf\n",
      "step: 8, train_loss: inf\n",
      "step: 9, train_loss: nan\n",
      "step: 10, train_loss: nan\n",
      "step: 11, train_loss: nan\n",
      "step: 12, train_loss: nan\n",
      "step: 13, train_loss: nan\n",
      "step: 14, train_loss: nan\n",
      "step: 15, train_loss: nan\n",
      "step: 16, train_loss: nan\n",
      "step: 17, train_loss: nan\n",
      "step: 18, train_loss: nan\n",
      "step: 19, train_loss: nan\n",
      "step: 20, train_loss: nan\n",
      "step: 21, train_loss: nan\n",
      "step: 22, train_loss: nan\n",
      "step: 23, train_loss: nan\n",
      "step: 24, train_loss: nan\n",
      "step: 25, train_loss: nan\n",
      "step: 26, train_loss: nan\n",
      "step: 27, train_loss: nan\n",
      "step: 28, train_loss: nan\n",
      "step: 29, train_loss: nan\n",
      "step: 30, train_loss: nan\n",
      "step: 31, train_loss: nan\n",
      "step: 32, train_loss: nan\n",
      "step: 33, train_loss: nan\n",
      "step: 34, train_loss: nan\n",
      "step: 35, train_loss: nan\n",
      "step: 36, train_loss: nan\n",
      "step: 37, train_loss: nan\n",
      "step: 38, train_loss: nan\n",
      "step: 39, train_loss: nan\n",
      "step: 40, train_loss: nan\n",
      "step: 41, train_loss: nan\n",
      "step: 42, train_loss: nan\n",
      "step: 43, train_loss: nan\n",
      "step: 44, train_loss: nan\n",
      "step: 45, train_loss: nan\n",
      "step: 46, train_loss: nan\n",
      "step: 47, train_loss: nan\n",
      "step: 48, train_loss: nan\n",
      "step: 49, train_loss: nan\n",
      "step: 50, train_loss: nan\n",
      "step: 51, train_loss: nan\n",
      "step: 52, train_loss: nan\n",
      "step: 53, train_loss: nan\n",
      "step: 54, train_loss: nan\n",
      "step: 55, train_loss: nan\n",
      "step: 56, train_loss: nan\n",
      "step: 57, train_loss: nan\n",
      "step: 58, train_loss: nan\n",
      "step: 59, train_loss: nan\n",
      "step: 60, train_loss: nan\n",
      "step: 61, train_loss: nan\n",
      "step: 62, train_loss: nan\n",
      "step: 63, train_loss: nan\n",
      "step: 64, train_loss: nan\n",
      "step: 65, train_loss: nan\n",
      "step: 66, train_loss: nan\n",
      "step: 67, train_loss: nan\n",
      "step: 68, train_loss: nan\n",
      "step: 69, train_loss: nan\n",
      "step: 70, train_loss: nan\n",
      "step: 71, train_loss: nan\n",
      "step: 72, train_loss: nan\n",
      "step: 73, train_loss: nan\n",
      "step: 74, train_loss: nan\n",
      "step: 75, train_loss: nan\n",
      "step: 76, train_loss: nan\n",
      "step: 77, train_loss: nan\n",
      "step: 78, train_loss: nan\n",
      "step: 79, train_loss: nan\n",
      "step: 80, train_loss: nan\n",
      "step: 81, train_loss: nan\n",
      "step: 82, train_loss: nan\n",
      "step: 83, train_loss: nan\n",
      "step: 84, train_loss: nan\n",
      "step: 85, train_loss: nan\n",
      "step: 86, train_loss: nan\n",
      "step: 87, train_loss: nan\n",
      "step: 88, train_loss: nan\n",
      "step: 89, train_loss: nan\n",
      "step: 90, train_loss: nan\n",
      "step: 91, train_loss: nan\n",
      "step: 92, train_loss: nan\n",
      "step: 93, train_loss: nan\n",
      "step: 94, train_loss: nan\n",
      "step: 95, train_loss: nan\n",
      "step: 96, train_loss: nan\n",
      "step: 97, train_loss: nan\n",
      "step: 98, train_loss: nan\n",
      "step: 99, train_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# リスト3.18を実行のためBoston house-pricesの読み込みが必要\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "\n",
    "# リスト3.18 住宅価格を推定するモデル\n",
    "\n",
    "# プレースホルダー(値未定の変数)の定義\n",
    "\n",
    "# 説明変数用のプレースホルダー\n",
    "x = tf.placeholder(tf.float32, (None, 13), name='x')\n",
    "# 正解データ（住宅価格）用のプレースホルダー\n",
    "y = tf.placeholder(tf.float32, (None, 1), name='y')\n",
    "\n",
    "# 説明変数を重み w で足し合わせただけの簡単なモデル\n",
    "w = tf.Variable(tf.random_normal((13, 1)))\n",
    "pred = tf.matmul(x, w)\n",
    "\n",
    "\n",
    "# リスト3.19 誤差の定義とtrain_stepの定義\n",
    "\n",
    "# 実測値と推定値の差の二乗の平均を誤差とする\n",
    "loss = tf.reduce_mean((y - pred)**2)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "# リスト3.20 学習のループ\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(100):\n",
    "        # train_stepがNoneを返すので、_で受けておく   # y_trainとyの次元を揃えるためにreshapeが必要\n",
    "        train_loss, _ = sess.run([loss, train_step], feed_dict = {x: x_train, y: y_train.reshape((-1, 1))})\n",
    "        print('step: {}, train_loss: {}'.format(step, train_loss))\n",
    "        \n",
    "    # 学習が終わったら、評価用データに対して予測してみる\n",
    "    pred_ = sess.run(pred, feed_dict={x: x_test})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
